{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vermaavi/food11\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "DATASET_PATH = \"/content/drive/My Drive/HSIFoodIngr-64\"  # Update the path to your dataset in Drive\n",
    "IMAGE_SIZE = (256, 256)\n",
    "NUM_CLASSES = 64\n",
    "\n",
    "# Function to load and preprocess hyperspectral images\n",
    "def load_images_and_labels(data_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    ingredient_mapping = {}\n",
    "    current_label = 0\n",
    "\n",
    "    for ingredient in os.listdir(data_path):\n",
    "        ingredient_path = os.path.join(data_path, ingredient)\n",
    "        if os.path.isdir(ingredient_path):\n",
    "            ingredient_mapping[current_label] = ingredient\n",
    "            for img_file in os.listdir(ingredient_path):\n",
    "                img_path = os.path.join(ingredient_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, IMAGE_SIZE)\n",
    "                images.append(img)\n",
    "                labels.append(current_label)\n",
    "            current_label += 1\n",
    "\n",
    "    images = np.array(images) / 255.0  # Normalize images\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, ingredient_mapping\n",
    "\n",
    "# Load dataset\n",
    "images, labels, ingredient_mapping = load_images_and_labels(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet-50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=list(ingredient_mapping.values())))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"/content/drive/My Drive/ResNet50_HSIFoodIngr64.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for inference\n",
    "loaded_model = tf.keras.models.load_model(\"/content/drive/My Drive/ResNet50_HSIFoodIngr64.h5\")\n",
    "\n",
    "# Predict on a new image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE) / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "new_image_path = \"/content/drive/My Drive/sample_image.jpg\"  # Update with your sample image path\n",
    "new_image = preprocess_image(new_image_path)\n",
    "prediction = np.argmax(loaded_model.predict(new_image), axis=1)\n",
    "predicted_ingredient = ingredient_mapping[prediction[0]]\n",
    "print(f\"Predicted Ingredient: {predicted_ingredient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
